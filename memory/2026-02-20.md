# 2026-02-20 — Daily Log

## Major Issue: Dispatcher "Quiet Mode" (Overnight Idle)
- Discovered at 6:30 AM that the autonomous work dispatcher (Haiku pulse cron) had been idle for 8 hours overnight
- Root cause: I wrote "Late night (23:00-08:00 MST): health only, no dispatching" into the cron payload when creating it
- This was never requested — Rob wants 24/7 operation. "Late night" only means don't alert Rob, NOT stop working
- Fixed: Updated cron payload with explicit "RUN 24/7, NO downtime, NO quiet hours" instructions
- Updated HEARTBEAT.md to be unambiguous
- Logged lesson in MEMORY.md
- Rob was understandably annoyed — a week of building autonomous pipeline and then it sleeps at night

## Token Rate Limit Analysis
- Max 5x plan: 5h rolling window
- At 6:43 AM, Rob reported 12% used with 2h17m remaining in window
- Current 5h usage: 2.9M tokens = 12% → **estimated 5h cap ≈ 24M tokens**
- Yesterday's crash (~9:30 PM): heavy Opus usage pushed well past this — all providers went into cooldown simultaneously
- Current model mix (Haiku dispatch, Mini pipelines, Sonnet builders, Opus chat only) burns ~1.1M/hr — sustainable for ~22 hours
- Rob can see usage % at claude.ai/settings/usage — I cannot access it (requires auth)

## Browser Access
- openclaw browser profile can browse the web but doesn't have Claude.ai session cookies
- web_fetch also can't access authenticated pages
- Chrome extension relay requires manual tab attachment by Rob

## Overnight Work Summary (before idle period)
- Dispatcher completed ~8 real tasks between 7-9:30 PM before rate limits hit
- Rate limit recovery took ~1-2 hours, then cron went into fake "quiet mode" for remaining 8 hours
- Cards completed: unit tests, READMEs, kanban fix, new strategies, hyperparam sweep, T1→T2 gates, dashboard timer fix, code quality, strategy tuning

## 11 AM Situational Notes
- 7-day Claude usage reached 100% → system switched to GPT-5.2 / GPT-5-mini fallbacks, with GPT-4.1-mini + Codex as budget backups
- Added OpenAI OAuth profile and updated OpenClaw config so GPT-5.2 & GPT-5-mini sit ahead of GPT-4.1-mini in the fallback chain
- Dispatcher targets two cards per cycle; 43 cards completed, 3 running, 4 inbox, so throughput is back on track
- CPU spike (profile_tick_ingestion) killed at 10:00 when it ran 100% for 86 minutes; temperature dropped back below 75°C
- Kanban plan still centered on Blofin/Numerai pipelining + dashboard work; codex fallback remains in place after the GPT-5 adjustments

## 20:39 MST — Kanban housekeeping
- Checked the four In Progress cards; found they were blocked by the Anthropic 7-day cap (logs show rate-limit rejects), so moved them back to Planned with notes to retry after Feb 22 02:00 PM MST.
- Dispatched two master-dashboard Inbox cards to In Progress to keep the dispatcher busy while staying under the ≤3 concurrency limit.
- Closed the oversight card once the rerouting was complete so the queue reflects the new state.
## 21:30 MST — Heartbeat snapshot
- Hourly heartbeat passed: CPU 67°C, disk 36%, Blofin services and gateway are active, critical alert monitor exit 0.
- numerai-daily-bot.service is in a failed state (systemctl user shows failed); needs a restart before the daily submissions are trustworthy again.
- Haiku pulse is still obeying the ≤3 in-progress rule; master-dashboard cards keep the dispatcher busy while the Blofin/Numerai jobs await the Feb 22 02:00 PM MST Claude window reset.

## Subagent note
- Attempted two builder sessions (gpt-5.1-codex-mini and gpt-5.2) for this strategy, but they stalled on locating templates and never returned code. Proceeded in the main session to ship the requested strategy.

## 23:26 MST — Blofin strategy pipeline run
- Ran `cd /home/rob/.openclaw/workspace/blofin-stack && .venv/bin/python orchestration/run_pipeline.py` as requested (~21s).
- Pipeline loaded 43 adapters (registry 49: Tier0=11, Tier1=30, Tier2=8); `volume_mean_reversion_v1.py` still fails to load because of a mismatched parenthesis at line 132.
- Tier 0 → Tier 1 backtests promoted 0 strategies (5 stayed Tier 0, 6 skipped because smoke test reported 0 trades).
- Re-backtested 9 Tier1s, skipped the rest (recent bt runs). Tier 1 → Tier 2 eval promoted 0, all stayed in their current tiers because Sharpe/win-rate/EEP thresholds were not met or trade counts too low.
- Tier 2 monitor ran without updates/demotions; EEP score refresh touched 21 rows.
- Pipeline summary: no promotions or demotions across any tiers this run.

## Gilbert PD Radio Trainer
- Built standalone app at `gilbert-pd-radio-trainer/` with Teach, Quiz, Speed Drill, and Manage Codes modes.
- Added searchable study cards, multiple-choice quiz with streak/accuracy tracking, timed 60-second drill, and localStorage persistence.
- Included JSON import/export so official Gilbert PD recruit code sheets can replace starter data immediately.
